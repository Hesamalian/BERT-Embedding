{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pre-trained BERT contextualized word embeddings",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hesamalian/BERT-Embedding/blob/master/Copy_of_Pre_trained_BERT_contextualized_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eot6_cHkIxHu",
        "colab_type": "code",
        "outputId": "11e1b6c1-216a-44b3-ca44-0cf53ab2c474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "!rm -rf bert\n",
        "!git clone https://github.com/google-research/bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Total 333 (delta 0), reused 0 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects: 100% (333/333), 277.61 KiB | 3.75 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plr13kC_IAoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('bert/')\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import collections\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pprint\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import modeling\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOt0hGU_vbEd",
        "colab_type": "code",
        "outputId": "c085ba27-bbb6-402d-ca4a-f64d593067e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.122.111.130:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 10:09:56.773096 140211060430720 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 17384077622496837368),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2600579398008595486),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6902390666166919801),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2721094601462557745),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 5018244474586534085),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5684809647906282631),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6817311112551601495),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5202788013627376479),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14106683048301966649),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 2731150568566336642),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 18274335325687322005)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nqW7nJWhdad",
        "colab_type": "code",
        "outputId": "725f5dc7-97e1-4d4a-f9d5-a23355fdbad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "!gsutil ls $BERT_PRETRAINED_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oLGerwRKCe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LAYERS = [-1,-2,-3,-4]\n",
        "NUM_TPU_CORES = 8\n",
        "MAX_SEQ_LENGTH = 87\n",
        "BERT_CONFIG = BERT_PRETRAINED_DIR + '/bert_config.json'\n",
        "CHKPT_DIR = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "VOCAB_FILE = BERT_PRETRAINED_DIR + '/vocab.txt'\n",
        "INIT_CHECKPOINT = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z5cIOXpHDUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "\n",
        "  def __init__(self, unique_id, text_a, text_b=None):\n",
        "    self.unique_id = unique_id\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2rw4F53H7A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self, unique_id, tokens, input_ids, input_mask, input_type_ids):\n",
        "    self.unique_id = unique_id\n",
        "    self.tokens = tokens\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.input_type_ids = input_type_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkYivQahH7uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn_builder(features, seq_length):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_unique_ids = []\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_input_type_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_unique_ids.append(feature.unique_id)\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_input_type_ids.append(feature.input_type_ids)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"unique_ids\":\n",
        "            tf.constant(all_unique_ids, shape=[num_examples], dtype=tf.int32),\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_type_ids\":\n",
        "            tf.constant(\n",
        "                all_input_type_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=False)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sitEUE6yJWxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(bert_config, init_checkpoint, layer_indexes, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    unique_ids = features[\"unique_ids\"]\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    input_type_ids = features[\"input_type_ids\"]\n",
        "\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=False,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=input_type_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "      raise ValueError(\"Only PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    scaffold_fn = None\n",
        "    (assignment_map,\n",
        "     initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(\n",
        "         tvars, init_checkpoint)\n",
        "    if use_tpu:\n",
        "\n",
        "      def tpu_scaffold():\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "        return tf.train.Scaffold()\n",
        "\n",
        "      scaffold_fn = tpu_scaffold\n",
        "    else:\n",
        "      tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    all_layers = model.get_all_encoder_layers()\n",
        "\n",
        "    predictions = {\n",
        "        \"unique_id\": unique_ids,\n",
        "    }\n",
        "\n",
        "    for (i, layer_index) in enumerate(layer_indexes):\n",
        "      predictions[\"layer_output_%d\" % i] = all_layers[layer_index]\n",
        "\n",
        "    output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7uS21ZTJYTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, seq_length, tokenizer):\n",
        "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "  features = []\n",
        "  for (ex_index, example) in enumerate(examples):\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "      tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "      # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "      # length is less than the specified length.\n",
        "      # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "      _truncate_seq_pair(tokens_a, tokens_b, seq_length - 3)\n",
        "    else:\n",
        "      # Account for [CLS] and [SEP] with \"- 2\"\n",
        "      if len(tokens_a) > seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids: 0     0   0   0  0     0 0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = []\n",
        "    input_type_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    input_type_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "      tokens.append(token)\n",
        "      input_type_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    input_type_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "      for token in tokens_b:\n",
        "        tokens.append(token)\n",
        "        input_type_ids.append(1)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      input_type_ids.append(1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < seq_length:\n",
        "      input_ids.append(0)\n",
        "      input_mask.append(0)\n",
        "      input_type_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == seq_length\n",
        "    assert len(input_mask) == seq_length\n",
        "    assert len(input_type_ids) == seq_length\n",
        "\n",
        "    if ex_index < 5:\n",
        "      tf.logging.info(\"*** Example ***\")\n",
        "      tf.logging.info(\"unique_id: %s\" % (example.unique_id))\n",
        "      tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "          [tokenization.printable_text(x) for x in tokens]))\n",
        "      tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "      tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "      tf.logging.info(\n",
        "          \"input_type_ids: %s\" % \" \".join([str(x) for x in input_type_ids]))\n",
        "\n",
        "    features.append(\n",
        "        InputFeatures(\n",
        "            unique_id=example.unique_id,\n",
        "            tokens=tokens,\n",
        "            input_ids=input_ids,\n",
        "            input_mask=input_mask,\n",
        "            input_type_ids=input_type_ids))\n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kv4oBpaJfKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "  \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "  # This is a simple heuristic which will always truncate the longer sequence\n",
        "  # one token at a time. This makes more sense than truncating an equal percent\n",
        "  # of tokens from each, since if one sequence is very short then each token\n",
        "  # that's truncated likely contains more information than a longer sequence.\n",
        "  while True:\n",
        "    total_length = len(tokens_a) + len(tokens_b)\n",
        "    if total_length <= max_length:\n",
        "      break\n",
        "    if len(tokens_a) > len(tokens_b):\n",
        "      tokens_a.pop()\n",
        "    else:\n",
        "      tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ybhvF0hJhTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_sequence(input_sentences):\n",
        "  examples = []\n",
        "  unique_id = 0\n",
        "  for sentence in input_sentences:\n",
        "    line = tokenization.convert_to_unicode(sentence)\n",
        "    examples.append(InputExample(unique_id=unique_id, text_a=line))\n",
        "    unique_id += 1\n",
        "  return examples\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kzMl3rQJjgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(input_text, dim=768):\n",
        "#   tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  layer_indexes = LAYERS\n",
        "\n",
        "  bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "\n",
        "  tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=VOCAB_FILE, do_lower_case=True)\n",
        "\n",
        "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=is_per_host))\n",
        "\n",
        "  examples = read_sequence(input_text)\n",
        "\n",
        "  features = convert_examples_to_features(\n",
        "      examples=examples, seq_length=MAX_SEQ_LENGTH, tokenizer=tokenizer)\n",
        "\n",
        "  unique_id_to_feature = {}\n",
        "  for feature in features:\n",
        "    unique_id_to_feature[feature.unique_id] = feature\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      layer_indexes=layer_indexes,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "  # or GPU.\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      predict_batch_size=BATCH_SIZE,\n",
        "      train_batch_size=BATCH_SIZE)\n",
        "\n",
        "  input_fn = input_fn_builder(\n",
        "      features=features, seq_length=MAX_SEQ_LENGTH)\n",
        "\n",
        "  # Get features\n",
        "  for result in estimator.predict(input_fn, yield_single_examples=True):\n",
        "    unique_id = int(result[\"unique_id\"])\n",
        "    feature = unique_id_to_feature[unique_id]\n",
        "    output = collections.OrderedDict()\n",
        "    for (i, token) in enumerate(feature.tokens):\n",
        "      layers = []\n",
        "      for (j, layer_index) in enumerate(layer_indexes):\n",
        "        layer_output = result[\"layer_output_%d\" % j]\n",
        "        layer_output_flat = np.array([x for x in layer_output[i:(i + 1)].flat])\n",
        "        layers.append(layer_output_flat)\n",
        "      output[token] = sum(layers)[:dim]\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJp9DY5WJmBv",
        "colab_type": "code",
        "outputId": "ae0b6a6d-0e70-456c-8dc7-494780569f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "embeddings = get_features([\"This is a test\"])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 10:10:34.048337 140211060430720 deprecation_wrapper.py:119] From bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0719 10:10:36.465833 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8526beaf28>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 10:10:36.469509 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpzxoszqx8\n",
            "W0719 10:10:36.734985 140211060430720 deprecation_wrapper.py:119] From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0719 10:10:36.739857 140211060430720 deprecation_wrapper.py:119] From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0719 10:10:36.971348 140211060430720 deprecation_wrapper.py:119] From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0719 10:10:37.040613 140211060430720 deprecation.py:323] From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0719 10:10:43.012125 140211060430720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0719 10:10:51.469869 140211060430720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:808: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhPGe469tmAT",
        "colab_type": "code",
        "outputId": "a15b100b-0b35-49a3-ffa4-b6b86461af2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "embeddings = get_features([sentences1[0]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 12:11:44.003319 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8533acef28>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:11:44.005318 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpxlshmy7p\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UqMGDFHJNx5",
        "colab_type": "code",
        "outputId": "ace1ba07-2ff3-43fd-cb04-ab49a87794cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "sentences1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the automobile and truck industries will diversify their powertrains considerably. Besides internal combustion engine (ICE) vehicles, popular automobiles will more than likely include plug-in hybrid electric vehicles (PHEVs), fully battery-powered electric vehicles (BEVs), and fuel cell electric vehicles (FCEVs) running on hydrogen. It’s still not clear precisely which vehicles customers will prefer; nevertheless, auto makers need to make strategic decisions today regarding their fuels and powertrains.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTMRWgELtzNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences1=['the automobile and truck industries will diversify their powertrains considerably. Besides internal combustion engine (ICE) vehicles, popular automobiles will more than likely include plug-in hybrid electric vehicles (PHEVs), fully battery-powered electric vehicles (BEVs), and fuel cell electric vehicles (FCEVs) running on hydrogen. It’s still not clear precisely which vehicles customers will prefer; nevertheless, auto makers need to make strategic decisions today regarding their fuels and powertrains.','This report provides a detailed analysis that compares the total cost of ownership (TCO) for each type of fuel and powertrain — today and projected through 2030. The estimates are based on factors such as required infrastructure, cost of fuel, taxes, regulations, mileage requirements, efficiency improvements, depreciation, maintenance, and insurance. Knowing the total cost of ownership can help auto makers generate a strategic road map during this period of disruption.','Although TCO will rise for the ICE, it will remain the most cost-effective vehicle for many drivers. However, technological advances in batteries, and other factors, will make BEVs increasingly competitive. FCEVs will also drop in cost. To be strategically ready for change, auto makers and suppliers should consider four broad actions today: prepare to ramp up production for the vehicles they choose to produce; optimize product costs across powertrains; focus on innovation (including more collaborative innovation); and recruit and train engineers familiar with the new powertrain alternatives.','It’s not necessary to consult a crystal ball to realize that, by the end of the next decade, the variety of automobiles on the road won’t resemble today’s relatively homogenous fleet at all. Today’s internal combustion engine (ICE) vehicles will be complemented by a mixture of powertrains, all legitimate suitors for customer attention. Besides','ICE vehicles, there will more than likely be plug-in hybrid electric vehicles (PHEVs), fully battery-powered electric vehicles (BEVs), and fuel cell electric vehicles (FCEVs) running on hydrogen.','categories, where BEVs are the best TCO option. This is primarily because for a low-range vehicle, the significant savings in fuel costs from BEVs compensate for the higher cost of battery powertrains.','However, for longer-range vehicles, ICE comes out on top. The price of an ICE powertrain for a given car does not increase with greater range (except perhaps for the minimal expense of a larger gas tank), whereas battery prices for electric vehicles (EVs) do rise as the range (and, hence, the size of the batteries) expands.','Between 2018 and 2030, cost differences among powertrains will change considerably, thus altering the TCO analyses. For each type of vehicle, here is how we anticipate that TCOs will be affected by these cost shifts:','To bring some clarity and direction to this challenge, Strategy&amp;, PwC’s strategy consulting business, recently undertook a detailed analysis that compares the total cost of ownership (TCO) for each powertrain currently and at landmark years through 2030. We projected the cost and required infrastructure to produce and distribute alternative fuels.','We plugged these factors into TCO analyses covering three separate automotive segments — budget, volume, and premium — and four different mileage ranges that a car can travel before refueling. In our estimates for 2030, we also included the impact of technological gains (mainly for batteries and power electronics), more stringent regulatory requirements for combustion engines, efficiency improvements, fuel costs, and depreciation. Taxes, maintenance, and insurance were also considered but were weighted less heavily.']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsBPHjR7uPE6",
        "colab_type": "code",
        "outputId": "817b64b6-80e4-4418-84eb-4bfdc1e18253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "results = [get_features([a]) for a in sentences1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 12:13:02.248336 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8522ae3d90>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:13:02.250980 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpf2u1lyfj\n",
            "W0719 12:13:29.853945 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8533357488>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:13:29.855920 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpq37x_tnn\n",
            "W0719 12:14:00.266627 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8523ea71e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:14:00.268734 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp6wm_9bxo\n",
            "W0719 12:14:30.978183 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f852462e400>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:14:30.981690 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpw8sj0jto\n",
            "W0719 12:15:05.249216 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8525275bf8>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:15:05.251222 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpeg4031sf\n",
            "W0719 12:15:40.621809 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8532eb6e18>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:15:40.624350 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmprwrddf58\n",
            "W0719 12:16:15.445503 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8532d93d08>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:16:15.448027 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpyel62me5\n",
            "W0719 12:16:50.085414 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f85253e86a8>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:16:50.087800 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpncelvnkg\n",
            "W0719 12:17:25.572566 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8523064158>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:17:25.574889 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmp00dyem29\n",
            "W0719 12:18:00.579633 140211060430720 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f85246802f0>) includes params argument, but params are not passed to Estimator.\n",
            "W0719 12:18:00.581577 140211060430720 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpm1g8jn4v\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f66lsI4TmYno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_vectorizer(model):\n",
        "    sent_vec =[]\n",
        "    numw = 0\n",
        "    for key,value in model.items():\n",
        "        try:\n",
        "            if numw == 0:\n",
        "                sent_vec = model[key]\n",
        "            else:\n",
        "                sent_vec = np.add(sent_vec, model[key])\n",
        "            numw+=1\n",
        "        except:\n",
        "            pass\n",
        "     \n",
        "    return np.asarray(sent_vec) / numw\n",
        "  \n",
        "  \n",
        "X=[]\n",
        "for res in results:\n",
        "    X.append(sent_vectorizer(res))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0g0oGcrLg87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "  \n",
        "from nltk.cluster import KMeansClusterer\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "import numpy as np \n",
        "  \n",
        "from sklearn import cluster\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mV_f6hqLW15",
        "colab_type": "code",
        "outputId": "4408de96-1cb3-4e4e-de9c-47c2aba5c537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "\n",
        "NUM_CLUSTERS=3\n",
        "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
        "assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
        "print (assigned_clusters)\n",
        "  \n",
        "  \n",
        "  \n",
        "# for index, sentence in enumerate(sentences):    \n",
        "#     print (str(assigned_clusters[index]) + \":\" + str(sentence))\n",
        " \n",
        "     \n",
        "     \n",
        "     \n",
        "kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS)\n",
        "kmeans.fit(X)\n",
        "  \n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_\n",
        "  \n",
        "# print (\"Cluster id labels for inputted data\")\n",
        "# print (labels)\n",
        "# print (\"Centroids data\")\n",
        "# print (centroids)\n",
        "  \n",
        "# print (\"Score (Opposite of the value of X on the K-means objective which is Sum of distances of samples to their closest cluster center):\")\n",
        "# print (kmeans.score(X))\n",
        "  \n",
        "# silhouette_score = metrics.silhouette_score(X, labels, metric='euclidean')\n",
        "  \n",
        "# print (\"Silhouette_score: \")\n",
        "# print (silhouette_score)\n",
        " \n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "from sklearn.manifold import TSNE\n",
        " \n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "np.set_printoptions(suppress=True)\n",
        " \n",
        "Y=model.fit_transform(X)\n",
        " \n",
        " \n",
        "plt.scatter(Y[:, 0], Y[:, 1], c=assigned_clusters, s=290,alpha=.5)\n",
        " \n",
        " \n",
        "for j in range(len(sentences1)):    \n",
        "   plt.annotate(assigned_clusters[j],xy=(Y[j][0], Y[j][1]),xytext=(0,0),textcoords='offset points')\n",
        "   print (\"%s %s\" % (assigned_clusters[j],  sentences1[j]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 0, 0, 2, 2, 2, 0, 1, 1]\n",
            "0 the automobile and truck industries will diversify their powertrains considerably. Besides internal combustion engine (ICE) vehicles, popular automobiles will more than likely include plug-in hybrid electric vehicles (PHEVs), fully battery-powered electric vehicles (BEVs), and fuel cell electric vehicles (FCEVs) running on hydrogen. It’s still not clear precisely which vehicles customers will prefer; nevertheless, auto makers need to make strategic decisions today regarding their fuels and powertrains.\n",
            "1 This report provides a detailed analysis that compares the total cost of ownership (TCO) for each type of fuel and powertrain — today and projected through 2030. The estimates are based on factors such as required infrastructure, cost of fuel, taxes, regulations, mileage requirements, efficiency improvements, depreciation, maintenance, and insurance. Knowing the total cost of ownership can help auto makers generate a strategic road map during this period of disruption.\n",
            "0 Although TCO will rise for the ICE, it will remain the most cost-effective vehicle for many drivers. However, technological advances in batteries, and other factors, will make BEVs increasingly competitive. FCEVs will also drop in cost. To be strategically ready for change, auto makers and suppliers should consider four broad actions today: prepare to ramp up production for the vehicles they choose to produce; optimize product costs across powertrains; focus on innovation (including more collaborative innovation); and recruit and train engineers familiar with the new powertrain alternatives.\n",
            "0 It’s not necessary to consult a crystal ball to realize that, by the end of the next decade, the variety of automobiles on the road won’t resemble today’s relatively homogenous fleet at all. Today’s internal combustion engine (ICE) vehicles will be complemented by a mixture of powertrains, all legitimate suitors for customer attention. Besides\n",
            "2 ICE vehicles, there will more than likely be plug-in hybrid electric vehicles (PHEVs), fully battery-powered electric vehicles (BEVs), and fuel cell electric vehicles (FCEVs) running on hydrogen.\n",
            "2 categories, where BEVs are the best TCO option. This is primarily because for a low-range vehicle, the significant savings in fuel costs from BEVs compensate for the higher cost of battery powertrains.\n",
            "2 However, for longer-range vehicles, ICE comes out on top. The price of an ICE powertrain for a given car does not increase with greater range (except perhaps for the minimal expense of a larger gas tank), whereas battery prices for electric vehicles (EVs) do rise as the range (and, hence, the size of the batteries) expands.\n",
            "0 Between 2018 and 2030, cost differences among powertrains will change considerably, thus altering the TCO analyses. For each type of vehicle, here is how we anticipate that TCOs will be affected by these cost shifts:\n",
            "1 To bring some clarity and direction to this challenge, Strategy&amp;, PwC’s strategy consulting business, recently undertook a detailed analysis that compares the total cost of ownership (TCO) for each powertrain currently and at landmark years through 2030. We projected the cost and required infrastructure to produce and distribute alternative fuels.\n",
            "1 We plugged these factors into TCO analyses covering three separate automotive segments — budget, volume, and premium — and four different mileage ranges that a car can travel before refueling. In our estimates for 2030, we also included the impact of technological gains (mainly for batteries and power electronics), more stringent regulatory requirements for combustion engines, efficiency improvements, fuel costs, and depreciation. Taxes, maintenance, and insurance were also considered but were weighted less heavily.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niATE/wd9CbDxqduj4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acRFZ4sZLo9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWiLz_VALVfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}